{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a95e4c6-72bb-4d22-842d-63ccff28952f",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e8dfed8-62d8-45fb-9f42-b0fe327fd702",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ceec70f-6ea2-4075-8528-a397d8738880",
   "metadata": {},
   "source": [
    "## Load science paper 5DL1 promoter data points "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e1ef150-0544-4b4c-b58f-4c88325309ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the data from file for 5DL1 promoter \n",
    "data=np.load(\"science_data_5DL1.npy\")\n",
    "\n",
    "# Extract x and y data\n",
    "x_data = data[:, 0]\n",
    "y_data = data[:, 1]\n",
    "\n",
    "# Get unique x values and their corresponding indices\n",
    "unique_x, unique_indices = np.unique(x_data, return_index=True)\n",
    "\n",
    "# Extract unique y values based on unique indices\n",
    "unique_y = y_data[unique_indices]\n",
    "\n",
    "# Create unique data array with x and y values\n",
    "unique_data = np.column_stack((unique_x, unique_y))\n",
    "\n",
    "# Convert mean and variance data to torch tensors\n",
    "mean_data = torch.from_numpy(unique_data[:, 0]).double()\n",
    "var_data = mean_data * torch.from_numpy(unique_data[:, 1]).double()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f641da-8997-41fa-b513-8a63ab0b8ac1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Differentiable Gillespie algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d0bce6f-8a85-4776-88e2-381a2d474615",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Stoichiometric matrix defining the effect of each reaction on the system\n",
    "stoic_matrix = torch.tensor([[2.0, 0.0],    # Reaction 1: Promoter state goes from -1 to +1\n",
    "                             [0.0, 1.0],    # Reaction 2: mRNA is produced\n",
    "                             [-2.0, 0.0],   # Reaction 3: Promoter state goes from +1 to -1\n",
    "                             [0.0, -1.0]])  # Reaction 4: Degradation of mRNA\n",
    "\n",
    "def state_jump(reaction_index, stoic_matrix):\n",
    "    \"\"\"\n",
    "    Calculate state jump vector based on the selected reaction index and stoichiometry matrix, where, \n",
    "    state vector -> state vector + state jump vector.\n",
    "\n",
    "    Arguments:\n",
    "        reaction_index: Selected reaction index\n",
    "        stoic_matrix: Stoichiometry matrix\n",
    "\n",
    "    Returns:\n",
    "        State jump vector\n",
    "    \"\"\" \n",
    "    return torch.sum(stoic_matrix * (torch.exp(-b_inv * (reaction_index - torch.arange(stoic_matrix.shape[0]))**2)).view(-1, 1), dim=0)\n",
    "\n",
    "def reaction_selection(breaks, random_num):\n",
    "    \"\"\"\n",
    "    Select reaction based on the transition points and a random number. Transition points are \n",
    "    given by the ratio of cumulative sum of rates and the total rate.\n",
    "\n",
    "    Arguments:\n",
    "        breaks: Transition points between [0,1]\n",
    "        random_num: Random number in [0,1]\n",
    "\n",
    "    Returns:\n",
    "        Index of the next reaction\n",
    "    \"\"\"\n",
    "    return torch.sum(torch.sigmoid(a_inv * (random_num - breaks)))\n",
    "\n",
    "def gillespie_simulation(poff_values, r, g):\n",
    "    \"\"\"\n",
    "    Perform differentiable Gillespie simulation for a 2-state promoter model.\n",
    "    \n",
    "    Arguments:\n",
    "        poff_values: Array of probabilities for promoter to be in OFF state. poff=koff/(kon+koff)\n",
    "        r: Rate of mRNA production.\n",
    "        g: Rate of mRNA degradation.\n",
    "        \n",
    "    Returns:\n",
    "        mean_final_states: Mean of the mRNA levels at the end of the simulation.\n",
    "        variances: Variance of the mRNA levels at the end of the simulation.\n",
    "    \"\"\"\n",
    "    # Initialize random seed for reproducibility\n",
    "    random_seed = torch.randint(1, 10000000, (1,))\n",
    "    torch.manual_seed(random_seed)\n",
    "\n",
    "    mean_final_states = torch.empty(len(unique_data))\n",
    "    variances = torch.empty(len(unique_data))\n",
    "    \n",
    "    for n in range(len(unique_data)):\n",
    "        poff = poff_values[n].unsqueeze(0)\n",
    "        \n",
    "        final_states = 0.0\n",
    "        final_states_squared = 0.0\n",
    "\n",
    "        for j in range(num_simulations):\n",
    "            # Initial 'levels':\n",
    "            # The first component of 'levels' is the promoter state, initialized to -1\n",
    "            # The second component of 'levels' is the mRNA level, initialized to 0.\n",
    "            levels = torch.stack([torch.tensor(-1.0), torch.tensor(0.0)])\n",
    "            current_time = 0.0\n",
    "\n",
    "            while current_time < sim_time:\n",
    "                # Calculate reaction propensities\n",
    "                propensities = torch.stack([(1/poff-1.0) * torch.sigmoid(-c*levels[0]), \n",
    "                                            r * torch.sigmoid(-c*levels[0]), \n",
    "                                            torch.tensor([1.0]) * torch.sigmoid(c * levels[0]), \n",
    "                                            g * levels[1]])\n",
    "                propensities = torch.relu(propensities)\n",
    "\n",
    "                # Sum of all propensities\n",
    "                total_propensity = propensities.sum()\n",
    "\n",
    "                # Time until next reaction\n",
    "                dt = -torch.log(torch.rand(1)) / total_propensity\n",
    "                current_time += dt.item()\n",
    "\n",
    "                if current_time >= sim_time:\n",
    "                    break\n",
    "\n",
    "                # Determine which reaction occurs and update the system state\n",
    "                breaks = (propensities[:-1] / total_propensity).cumsum(dim=0)\n",
    "                reaction_index = reaction_selection(breaks, torch.rand(1))\n",
    "                levels = levels + state_jump(reaction_index, stoic_matrix)\n",
    "                levels[1] = torch.relu(levels[1])  # Ensure non-negative values for the mRNA number\n",
    "\n",
    "            # Accumulate mRNA level and its square\n",
    "            final_states += levels[1]\n",
    "            final_states_squared += levels[1] ** 2\n",
    "\n",
    "        # Calculate mean and variance of mRNA levels\n",
    "        mean_final_state = final_states / num_simulations\n",
    "        variance = final_states_squared / num_simulations - mean_final_state ** 2\n",
    "        \n",
    "        mean_final_states[n] = mean_final_state\n",
    "        variances[n] = variance\n",
    "\n",
    "    return mean_final_states, variances\n",
    "\n",
    "def loss_function(mean_final_states, variances):\n",
    "    \"\"\"\n",
    "    Loss function that calculates the mean squared error of the simulation results against data.\n",
    "\n",
    "    Arguments:\n",
    "        mean_final_states: Mean of the mRNA levels at the end of the simulation.\n",
    "        variances: Variance of the mRNA levels at the end of the simulation.\n",
    "        \n",
    "    Returns:\n",
    "        Loss value\n",
    "    \"\"\"\n",
    "    return torch.mean((mean_final_states - mean_data)**2 + (variances**0.5 - var_data**0.5)**2)\n",
    "\n",
    "# Define a function to write data to a file\n",
    "def write_to_file(filename, *args):\n",
    "    with open(filename, 'a') as file:\n",
    "        file.write(' '.join(map(str, args)) + '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a71cda-b4ac-434f-94be-71100e2d9f9d",
   "metadata": {},
   "source": [
    "## Gradient descent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520ce75d-d993-418b-8e1a-c78b55982a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed for reproducibility \n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Define simulation hyperparameters\n",
    "num_iterations = 1000\n",
    "num_simulations = 200\n",
    "sim_time = 0.2\n",
    "a_inv = 200.0\n",
    "b_inv =20.0\n",
    "c = 20.0\n",
    "\n",
    "# Initialize parameters with random values\n",
    "poff_values = torch.nn.Parameter(torch.linspace(0.03, 0.97, len(unique_data)))\n",
    "r = torch.nn.Parameter((1e+2) * torch.rand(1))\n",
    "g = torch.nn.Parameter((1e+1) * torch.rand(1))\n",
    "\n",
    "# Define the Adam optimizer and include all parameters that require gradients\n",
    "optimizer = optim.Adam([poff_values, r, g], lr=0.1)\n",
    "\n",
    "# Define filenames for saving results\n",
    "filename1 = \"learning_science_5DL1_poff.txt\"\n",
    "if os.path.exists(filename1):\n",
    "    os.remove(filename1)   \n",
    "filename2 = \"learning_science_5DL1.txt\"\n",
    "if os.path.exists(filename2):\n",
    "    os.remove(filename2)\n",
    "\n",
    "# Main optimization loop\n",
    "for iteration in range(num_iterations):\n",
    "    \n",
    "    # Forward differentiable Gillespie simulation\n",
    "    mean_final_states, variances = gillespie_simulation(poff_values, r, g)\n",
    "    \n",
    "    # Compute the loss for the current iteration\n",
    "    loss = loss_function(mean_final_states, variances)\n",
    "\n",
    "    # Zero the gradients to prepare for backward pass\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Compute the gradient of the loss with respect to parameters\n",
    "    loss.backward()\n",
    "\n",
    "    # Clip gradients to prevent exploding gradients problem\n",
    "    torch.nn.utils.clip_grad_norm_([poff_values, r, g], max_norm=1.0)\n",
    "\n",
    "    # Update the parameters using the optimizer\n",
    "    optimizer.step()\n",
    "\n",
    "    # Clamp r and g to ensure they are within valid range\n",
    "    r.data = torch.clamp(r.data, min=1.0)\n",
    "    g.data = torch.clamp(g.data, min=1.0, max=r.item())\n",
    "    poff_values.data = torch.clamp(poff_values, min=0.01, max=0.98)\n",
    "    poff_values.data, _ = torch.sort(poff_values.data)\n",
    "\n",
    "    # Save the values of the parameters after each iteration\n",
    "    if iteration % 1 == 0:\n",
    "        write_to_file(filename2, iteration, r.item(), g.item(), r.item() / g.item(), loss.item())\n",
    "        write_to_file(filename1, poff_values.tolist(), loss.item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-default] *",
   "language": "python",
   "name": "conda-env-.conda-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
