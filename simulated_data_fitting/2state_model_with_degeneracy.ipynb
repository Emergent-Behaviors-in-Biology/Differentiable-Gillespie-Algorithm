{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a95e4c6-72bb-4d22-842d-63ccff28952f",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e8dfed8-62d8-45fb-9f42-b0fe327fd702",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f641da-8997-41fa-b513-8a63ab0b8ac1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Define differentiable Gillespie algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d0bce6f-8a85-4776-88e2-381a2d474615",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the stoichiometry matrix for the reactions\n",
    "stoic_matrix = torch.tensor([[2.0, 0.0],    # Reaction 1: Promoter state goes from -1 to +1\n",
    "                             [0.0, 1.0],    # Reaction 2: mRNA is produced\n",
    "                             [-2.0, 0.0],   # Reaction 3: Promoter state goes from +1 to -1\n",
    "                             [0.0, -1.0]])  # Reaction 4: Degradation of mRNA\n",
    "\n",
    "# Define a function to compute the state jump\n",
    "def state_jump(reaction_index, stoic_matrix):\n",
    "    \"\"\"\n",
    "    Calculate state jump vector based on the selected reaction index and stoichiometry matrix, where, \n",
    "    state vector -> state vector + state jump vector.\n",
    "\n",
    "    Arguments:\n",
    "        reaction_index: Selected reaction index\n",
    "        stoic_matrix: Stoichiometry matrix\n",
    "\n",
    "    Returns:\n",
    "        State jump vector\n",
    "    \"\"\"\n",
    "    return torch.sum(stoic_matrix * (torch.exp(-b_inv* (reaction_index - torch.arange(stoic_matrix.shape[0]))**2)).view(-1, 1), dim=0)\n",
    "\n",
    "# Define a function to select the reaction based on reaction selection thresholds\n",
    "def reaction_selection(breaks, random_num):\n",
    "    \"\"\"\n",
    "    Select reaction based on the transition points and a random number. Transition points are \n",
    "    given by the ratio of cumulative sum of rates and the total rate.\n",
    "\n",
    "    Arguments:\n",
    "        breaks: Transition points between [0,1]\n",
    "        random_num: Random number in [0,1]\n",
    "\n",
    "    Returns:\n",
    "        Index of the next reaction\n",
    "    \"\"\"\n",
    "    return torch.sum(torch.sigmoid(a_inv * (random_num - breaks)))\n",
    "\n",
    "# Define the Gillespie simulation function\n",
    "def gillespie_simulation(poff, r, g, num_simulations, sim_time, a_inv, b_inv, c):\n",
    "    \"\"\"\n",
    "    Perform differentiable Gillespie simulation for a 2-state promoter model.\n",
    "    \n",
    "    Arguments:\n",
    "        poff: Promoter probability to be in OFF (-1) state. poff=koff/(koff+kon).\n",
    "        r: Rate of mRNA production.\n",
    "        g: Rate of mRNA degradation.\n",
    "        num_simulations: Number of simulations to run.\n",
    "        sim_time: Simulation time.\n",
    "        a_inv: Inverse parameter for reaction selection.\n",
    "        b_inv : Inverse parameter for state jump calculation.\n",
    "        c: Sigmoid slope parameter for propensities.\n",
    "        \n",
    "    Returns:\n",
    "        mean_final_state: Mean of the mRNA levels at the end of the simulation.\n",
    "        variance: Variance of the mRNA levels at the end of the simulation.\n",
    "    \"\"\"\n",
    "    # Initialize random seed for reproducibility\n",
    "    random_seed = torch.randint(1, 10000000, (1,))\n",
    "    torch.manual_seed(random_seed)\n",
    "    final_states = 0.0\n",
    "    final_states_squared = 0.0\n",
    "\n",
    "    # Main simulation loop\n",
    "    for j in range(num_simulations):\n",
    "        # Initial 'levels':\n",
    "        # The first component of 'levels' is the promoter state, initialized to -1\n",
    "        # The second component of 'levels' is the mRNA level, initailized to 0.\n",
    "        levels = torch.stack([torch.tensor(-1.0), torch.tensor(0.0)])\n",
    "        current_time = 0.0\n",
    "\n",
    "        # Main simulation loop\n",
    "        while current_time < sim_time:\n",
    "            # Calculate reaction propensities\n",
    "            propensities = torch.stack([(1/poff-1.0) *torch.sigmoid(-c*levels[0]),       # Rate of promoter state switching from -1 to +1\n",
    "                                        r*torch.sigmoid(-c*levels[0]),                   # Rate of mRNA production\n",
    "                                        torch.tensor([1.0])*torch.sigmoid(c*levels[0]),  # Rate of promoter state switching from +1 to -1\n",
    "                                        g*levels[1]])                                    # Rate of mRNA degradation\n",
    "\n",
    "            # Calculate total propensity\n",
    "            total_propensity = propensities.sum()\n",
    "\n",
    "            # Generate a random number to determine time to next reaction\n",
    "            dt = -torch.log(torch.rand(1)) / total_propensity\n",
    "            current_time += dt.item()\n",
    "\n",
    "            # Check if the simulation exceeds sim_time. If it exceeds, quit the simulation.\n",
    "            if current_time >= sim_time:\n",
    "                break\n",
    "\n",
    "            # Update state\n",
    "            breaks = (propensities[:-1] / total_propensity).cumsum(dim=0)\n",
    "            reaction_index = reaction_selection(breaks, torch.rand(1))\n",
    "            levels = levels + state_jump(reaction_index, stoic_matrix)\n",
    "            levels[1] = torch.relu(levels[1]) \n",
    "\n",
    "        # Accumulate final states after each sumulation\n",
    "        final_states += levels[1]\n",
    "        final_states_squared += levels[1] ** 2\n",
    "\n",
    "    # Calculate mean and variance of mRNA levels (from the accumulated final states)\n",
    "    mean_final_state = final_states / num_simulations\n",
    "    variance = final_states_squared / num_simulations - mean_final_state ** 2\n",
    "\n",
    "    # Return mean mRNA level and variance\n",
    "    return mean_final_state, variance\n",
    "\n",
    "# Define a function to write data to a file\n",
    "def write_to_file(filename, *args):\n",
    "    with open(filename, 'a') as file:\n",
    "        file.write(' '.join(map(str, args)) + '\\n')\n",
    "        \n",
    "# Define the loss function \n",
    "def loss_function(mean_final_state, variance, target_mean, target_std):\n",
    "    \"\"\"\n",
    "    Calculates the mean squared error of the simulation results against data\n",
    "    \"\"\"\n",
    "    return (mean_final_state - target_mean) ** 2 + (variance ** 0.5 - target_std) ** 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94bbe818-2d17-43b0-acaf-12cda546a493",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23eec6c-2239-4ab5-b69b-689d3113c295",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set seed for reproducibility \n",
    "torch.manual_seed(40)\n",
    "\n",
    "# Define simulation hyperparameters\n",
    "num_simulations = 50\n",
    "sim_time = 10.0\n",
    "a_inv = 200.0\n",
    "b_inv =20.0\n",
    "c = 20.0\n",
    "num_iterations = 130\n",
    "\n",
    "# Load the sample random rates from a file\n",
    "sample = np.load(\"random_rates.npy\")\n",
    "\n",
    "# Define the filename to write data\n",
    "filename = \"2state_model_with_deg.txt\"\n",
    "\n",
    "# Remove the file if it already exists\n",
    "if os.path.exists(filename):\n",
    "    os.remove(filename)\n",
    "\n",
    "# Loop through each sample rate set\n",
    "for i in range(sample.shape[0]):\n",
    "\n",
    "    # Initialize parameters\n",
    "    poff = torch.nn.Parameter((1.0 / (1.0 + sample[i, 0])) * (10 ** (-1 + 2 * torch.rand(1)))) # poff=(1/(1+kon))\n",
    "    while True:\n",
    "        r = torch.nn.Parameter(sample[i, 1] * (10 ** (-1 + 2 * torch.rand(1))))\n",
    "        g = torch.nn.Parameter(sample[i, 2] * (10 ** (-1 + 2 * torch.rand(1))))\n",
    "        if g < r:\n",
    "            break\n",
    "\n",
    "    # Define the Adam optimizer\n",
    "    optimizer = optim.Adam([poff, r, g], lr=0.1)\n",
    "\n",
    "    # Set target mean and standard deviation\n",
    "    target_mean = sample[i, 3]\n",
    "    target_std = sample[i, 4]\n",
    "\n",
    "    # Loop through each iteration\n",
    "    for iteration in range(num_iterations):\n",
    "\n",
    "        # Forward differentiable Gillespie simulation\n",
    "        mean_final_state, variance = gillespie_simulation(poff, r, g, num_simulations, sim_time, a_inv, b_inv, c)\n",
    "\n",
    "        # Compute the loss for the current iteration\n",
    "        loss = loss_function(mean_final_state, variance, target_mean, target_std)\n",
    "\n",
    "        # Zero the gradients to prepare for backward pass\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Compute the gradient of the loss with respect to parameters\n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_([poff, r, g], max_norm=0.2)\n",
    "\n",
    "        # Update the parameters using the optimizer\n",
    "        optimizer.step()\n",
    "\n",
    "        # Clamp the parameter values to certain bounds\n",
    "        poff.data = torch.clamp(poff.data, min=1 / (1 + 100), max=1 / (1 + 0.1))\n",
    "        r.data = torch.clamp(r.data, min=0.1, max=100.0)\n",
    "        g.data = torch.clamp(g.data, min=0.1, max=r.data.item())\n",
    "\n",
    "        # Save the values of the parameters and the loss every iterations\n",
    "        if iteration % 1 == 0:\n",
    "            write_to_file(filename, i, iteration, (1 / poff.item()) - 1.0, r.item(), g.item(), mean_final_state.item(), (variance ** 0.5).item()\n",
    "                         , (poff * r / g).item(), loss.item())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-default] *",
   "language": "python",
   "name": "conda-env-.conda-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
