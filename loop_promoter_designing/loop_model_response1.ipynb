{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9fe1742-e33b-41a4-9e24-c93719c90fb1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d944e9a4-ed61-4bbf-8bdf-c3eadf196e09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1997275-46bc-4b07-8bb7-7f157defb6db",
   "metadata": {},
   "source": [
    "## Desired response curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db279b35-295f-4396-83cf-1c23c59f330f",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"loop_model_forward_exact_curve.txt\"\n",
    "\n",
    "# Check if the file already exists, and remove it if it does\n",
    "if os.path.exists(filename):\n",
    "    os.remove(filename)\n",
    "\n",
    "# Function to write data to a file\n",
    "def write_to_file(filename, *args):\n",
    "    with open(filename, 'a') as file:\n",
    "        file.write(' '.join(map(str, args)) + '\\n')\n",
    "\n",
    "# Function to perform exact Gillespie simulation for the dorsal concentration c \n",
    "def gillespie_simulation(c, num_simulations=600, sim_time=20.0):\n",
    "    mrna_prod_rates = torch.tensor([])\n",
    "\n",
    "    # Perform simulations\n",
    "    for i in range(num_simulations):\n",
    "        time_points = torch.tensor([0])  # Initialize time points\n",
    "        states = torch.tensor([0])  # Initialize the sequence of promoter states\n",
    "        state = torch.tensor(0)  # Initialize current promoter state\n",
    "        active_time = torch.tensor(0)  # Initialize active time (time duration for which the promoter is in either state 2 or 3)\n",
    "        current_time = 0.0  # Initialize current time\n",
    "        \n",
    "        # Perform simulation until sim_time is reached\n",
    "        while current_time < sim_time:\n",
    "            # Calculate rates based on the current state\n",
    "            forward_rate = k_for(c, state)   # Rate at which promoter state moves forward\n",
    "            backward_rate = k_back(c, state) # Rate at which promoter state moves backward\n",
    "            total_rate = forward_rate + backward_rate \n",
    "\n",
    "            # Generate time step based on total rate\n",
    "            dt = (1/total_rate) * torch.log(1/torch.rand(1))\n",
    "\n",
    "            # Update time\n",
    "            time_points = torch.cat((time_points, time_points[-1] + dt), dim=0)\n",
    "\n",
    "            # Update state\n",
    "            if torch.rand(1) < forward_rate / total_rate:\n",
    "                state = (state + 1) % 4 \n",
    "            else:\n",
    "                state = (state - 1) % 4 \n",
    "            states = torch.cat((states, state.view(1)), dim=0)\n",
    "\n",
    "            # Accumulate active time if in states 2 or 3\n",
    "            if states[-2] == 2 or states[-2] == 3:\n",
    "                active_time=active_time+dt\n",
    "            current_time = time_points[-1]\n",
    "\n",
    "        # Calculate the mRNA production rate for each simulation and store\n",
    "        mrna_prod_rates = torch.cat((mrna_prod_rates, (active_time/current_time).view(1)), dim=0)\n",
    "        \n",
    "    # Calculate the mean mRNA production rate over all simulations\n",
    "    mean = torch.mean(mrna_prod_rates)\n",
    "\n",
    "    return mean\n",
    "\n",
    "# Function to calculate forward rates\n",
    "def k_for(c, state):\n",
    "    if state == 0:\n",
    "        k = c * k_b\n",
    "    elif state == 1:\n",
    "        k = n_ab * k_a\n",
    "    elif state == 2:\n",
    "        k = n_ua * k_u\n",
    "    elif state == 3:\n",
    "        k = k_i\n",
    "    return k\n",
    "\n",
    "# Function to calculate backward rates\n",
    "def k_back(c, state):\n",
    "    if state == 0:\n",
    "        k = k_a\n",
    "    elif state == 1:\n",
    "        k = k_u\n",
    "    elif state == 2:\n",
    "        k = n_ib * k_i\n",
    "    elif state == 3:\n",
    "        k = c * n_ba * k_b\n",
    "    return k\n",
    "\n",
    "# Set the value of parameters\n",
    "c_range = torch.logspace(np.log10(10), np.log10(5000), 10)  # Dorsal protein concentration range\n",
    "k_b = 0.02\n",
    "k_u = 2.0\n",
    "k_a = 0.3\n",
    "k_i = 2.5\n",
    "n_ib = 0.3\n",
    "n_ab = 3.0\n",
    "n_ba = 1.5\n",
    "n_ua = 1.5\n",
    "\n",
    "torch.manual_seed(42)\n",
    "# Perform simulations for each concentration in the range\n",
    "for c in c_range:\n",
    "    mean = gillespie_simulation(c)\n",
    "    write_to_file(filename, c.item(), mean.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d6d25f-7cf8-4bfc-abb1-ba6ee187d631",
   "metadata": {},
   "source": [
    "## Define differentiable Gillespie algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2586357f-209e-4f30-a0a1-fc9994f554a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the stoichiometric matrix\n",
    "stoic_matrix= torch.tensor([[1.0], # Reaction1: Promoter state moves forward \n",
    "                          [-1.0]]) # Reaction2: Promoter state moves backward \n",
    "\n",
    "# Function to calculate state jump\n",
    "def state_jump(reaction_index, stoic_matrix):\n",
    "    \"\"\"\n",
    "    Calculate state jump vector based on the selected reaction index and stoichiometry matrix, where, \n",
    "    state vector -> state vector + state jump vector.\n",
    "\n",
    "    Arguments:\n",
    "        reaction_index: Selected reaction index\n",
    "        stoic_matrix: Stoichiometry matrix\n",
    "\n",
    "    Returns:\n",
    "        State jump vector\n",
    "    \"\"\"\n",
    "    return torch.sum(stoic_matrix * (torch.exp(-b_inv * (reaction_index - torch.arange(stoic_matrix.shape[0]))**2)).view(-1, 1), dim=0)\n",
    "\n",
    "# Function to select reaction\n",
    "def reaction_selection(breaks, random_num):\n",
    "    \"\"\"\n",
    "    Select reaction based on the transition points and a random number. Transition points are \n",
    "    given by the ratio of cumulative sum of rates and the total rate.\n",
    "\n",
    "    Arguments:\n",
    "        breaks: Transition points between [0,1]\n",
    "        random_num: Random number in [0,1]\n",
    "\n",
    "    Returns:\n",
    "        Index of the next reaction\n",
    "    \"\"\"\n",
    "    return torch.sum(torch.sigmoid(a_inv * (random_num - breaks)))\n",
    "\n",
    "# Function for Gillespie simulation\n",
    "def gillespie_simulation(k_b, k_u, k_a, k_i, n_ib, n_ab, n_ba, n_ua, num_simulations, sim_time, a_inv, b_inv, cc):\n",
    "    \"\"\"\n",
    "    Perform differentiable Gillespie simulation for the 4-state loop promoter model.\n",
    "    \n",
    "    Arguments:\n",
    "        k_b, k_u, k_a, k_i, n_ib, n_ab, n_ba, n_ua: Rates involved in the loop model.\n",
    "        num_simulations: Number of simulations to run.\n",
    "        sim_time: Simulation time.\n",
    "        a_inv: Inverse parameter for reaction selection.\n",
    "        b_inv : Inverse parameter for state jump calculation.\n",
    "        cc: Sigmoid slope parameter for propensities (rates).\n",
    "        \n",
    "    Returns:\n",
    "        mean_values: Mean of the mRNA levels at the end of the simulation.\n",
    "    \"\"\"\n",
    "    random_seed = torch.randint(1, 10000000, (1,))\n",
    "    torch.manual_seed(random_seed)\n",
    "    mean_values = torch.tensor([]) # Tensor to store the mean mRNA production rate for each concentration c\n",
    "    \n",
    "    # Loop over the concentration c \n",
    "    for c in c_range:\n",
    "        mrna_prod_rates = torch.tensor([]) # Empty tensor to store the mRNA production rates after each simulation\n",
    "        for j in range(num_simulations):\n",
    "            state = torch.tensor(0.0)  # Initialize the current state of the promoter to 0\n",
    "            states = torch.tensor([0]) # Tensor to store the sequence of promoter states\n",
    "            active_time = 0.0          # Time spent in state 2 or 3\n",
    "            current_time = 0.0         # Total time\n",
    "            \n",
    "            while current_time < sim_time:\n",
    "                \n",
    "                # Calculate reaction propensities (rates)\n",
    "                forward_rate = k_for(c, k_b, k_u, k_a, k_i, n_ab, n_ba, n_ua, state) # Rate at which promoter state moves forward\n",
    "                backward_rate = k_back(c, k_b, k_u, k_a, k_i, n_ib, n_ba, state)     # Rate at which promoter state moves backward\n",
    "                propensities = torch.stack([forward_rate, backward_rate])\n",
    "\n",
    "                # Calculate total propensity\n",
    "                total_propensity = propensities.sum()\n",
    "\n",
    "                # Generate a random number to determine time to next reaction\n",
    "                dt = -torch.log(torch.rand(1)) / total_propensity\n",
    "                current_time += dt.item()\n",
    "\n",
    "                # Check if the simulation exceeds sim_time\n",
    "                if current_time >= sim_time:\n",
    "                    break\n",
    "\n",
    "                # Update state\n",
    "                breaks = (propensities[:-1] / total_propensity).cumsum(dim=0) # Transition points between [0,1]\n",
    "                reaction_index = reaction_selection(breaks, torch.rand(1)) # Choose index of next promoter state jump\n",
    "                state = state + state_jump(reaction_index, stoic_matrix) # Update promoter state\n",
    "                state = state % 4 # Implement periodicity \n",
    "                state = torch.relu(state) - torch.relu(state - 3) - 3.0 * torch.sigmoid(200 * (state - 3.5))\n",
    "                states = torch.cat((states, state), dim=0)\n",
    "                active_time = active_time + dt * (torch.sigmoid(200 * (states[-2] - 1.5))) # Add the waiting time to active_time if the promoter was in state > 1.5\n",
    "                \n",
    "            # Accumulate mrna production rates after each sumulation\n",
    "            mrna_prod_rates = torch.cat((mrna_prod_rates, active_time / current_time), dim=0)\n",
    "            \n",
    "        # Calculate mean mRNA production rate (from the accumulated mrna production rates)\n",
    "        mean = torch.mean(mrna_prod_rates)\n",
    "        \n",
    "        # Store the mean mRNA production rate for each concentration c\n",
    "        mean_values = torch.cat((mean_values, mean.view(1)), dim=0)\n",
    "\n",
    "    return mean_values\n",
    "\n",
    "# Function for forward rates\n",
    "def k_for(c, k_b, k_u, k_a, k_i, n_ab, n_ba, n_ua, state):\n",
    "    out = (n_ab * k_a - c * k_b) * torch.sigmoid(cc * (state - 0.5)) + \\\n",
    "          (n_ua * k_u - n_ab * k_a) * torch.sigmoid(cc * (state - 1.5)) + \\\n",
    "          (k_i - n_ua * k_u) * torch.sigmoid(cc * (state - 2.5)) + \\\n",
    "          (c * k_b)\n",
    "    return out\n",
    "\n",
    "# Function for backward rates\n",
    "def k_back(c, k_b, k_u, k_a, k_i, n_ib, n_ba, state):\n",
    "    out = (k_u - k_a) * torch.sigmoid(cc * (state - 0.5)) + \\\n",
    "          (n_ib * k_i - k_u) * torch.sigmoid(cc * (state - 1.5)) + \\\n",
    "          (c * n_ba * k_b - n_ib * k_i) * torch.sigmoid(cc * (state - 2.5)) + \\\n",
    "          (k_a)\n",
    "    return out\n",
    "\n",
    "# Define the loss function \n",
    "def loss_function(mean_values, target_mean_values):\n",
    "    \"\"\"\n",
    "    Loss function that calculates the mean squared error of the simulation results against data.\n",
    "    \"\"\"\n",
    "    return torch.mean((mean_values - target_mean_values)**2)\n",
    "\n",
    "# Function to write results to file\n",
    "def write_to_file(filename, *args):\n",
    "    with open(filename, 'a') as file:\n",
    "        file.write(' '.join(map(str, args)) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81be6ab-646c-4203-a9ac-83d78a683a29",
   "metadata": {},
   "source": [
    "## Gradient descent on the 7-dimensional parameter space "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69da0324-5125-494b-a3ee-c12611a19492",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the desired mean mRNA production rates from a file\n",
    "data = torch.tensor(np.loadtxt(\"loop_model_forward_exact_curve.txt\"))\n",
    "c_values = data[:, 0] # Dorsal concentration \n",
    "target_mean_values = data[:, 1] # mean mRNA production rate\n",
    "\n",
    "filename = \"loop_model_learning_results.txt\" # File to store the learning progress\n",
    "\n",
    "# Check if the file exists and remove it if it does\n",
    "if os.path.exists(filename):\n",
    "    os.remove(filename)\n",
    "        \n",
    "# Seed for reproducibility\n",
    "random.seed(1) \n",
    "\n",
    "# Initializing the parameter values\n",
    "k_b_tensor = torch.tensor(2.0)\n",
    "k_u_tensor =  torch.tensor(random.uniform(0.1, 10.0), requires_grad=True)\n",
    "k_a_tensor = torch.tensor(random.uniform(0.1, 1.0), requires_grad=True)\n",
    "k_i_tensor = torch.tensor(random.uniform(0.1, 10.0), requires_grad=True)\n",
    "n_ib_tensor = torch.tensor(random.uniform(0.1, 1.0), requires_grad=True)\n",
    "n_ab_tensor =  torch.tensor(random.uniform(1.0, 10.0), requires_grad=True)\n",
    "n_ba_tensor = torch.tensor(random.uniform(0.1, 10.0), requires_grad=True)\n",
    "n_ua_tensor = torch.tensor(random.uniform(0.1, 10.0), requires_grad=True)\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = optim.Adam([k_u_tensor, k_a_tensor, k_i_tensor, n_ib_tensor, n_ab_tensor\n",
    "        , n_ba_tensor, n_ua_tensor], lr=0.1)\n",
    "\n",
    "# Hyperparameters\n",
    "num_iterations = 2000\n",
    "num_simulations=20\n",
    "sim_time=20.0\n",
    "a_inv=200.0\n",
    "b_inv=20.0\n",
    "cc=20.0\n",
    "\n",
    "# Dorsal protein concentration range\n",
    "c_range = 0.01*torch.logspace(np.log10(10), np.log10(5000), 10) \n",
    "\n",
    "torch.manual_seed(42)\n",
    "for iteration in range(num_iterations):\n",
    "    \n",
    "    # Perform Gillespie simulation to compute mean values\n",
    "    mean_values = gillespie_simulation(k_b_tensor, k_u_tensor, k_a_tensor, k_i_tensor, n_ib_tensor, n_ab_tensor\n",
    "        , n_ba_tensor, n_ua_tensor)\n",
    "\n",
    "    # Compute the loss for the current iteration\n",
    "    loss = loss_function(mean_values, target_mean_values)\n",
    "\n",
    "    # Zero the gradients to prepare for backward pass\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Compute the gradient of the loss with respect to parameters\n",
    "    loss.backward()\n",
    "\n",
    "    # Update the parameters using the optimizer\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Enforce valid parameter constraints for the parameters \n",
    "    k_u_tensor.data = torch.clamp(k_u_tensor.data, min=0.01)\n",
    "    k_a_tensor.data = torch.clamp(k_a_tensor.data, min=0.01)\n",
    "    k_i_tensor.data = torch.clamp(k_i_tensor.data, min=0.01)\n",
    "    n_ib_tensor.data = torch.clamp(n_ib_tensor.data, min=0.01)\n",
    "    n_ab_tensor.data = torch.clamp(n_ab_tensor.data, min=1.0)\n",
    "    n_ba_tensor.data = torch.clamp(n_ba_tensor.data, min=0.01)\n",
    "    n_ua_tensor.data = torch.clamp(n_ua_tensor.data, min=0.01)\n",
    "\n",
    "    \n",
    "    # Write the results to the file after each iteration\n",
    "    write_to_file(filename, iteration, k_b_tensor.item(), k_u_tensor.item(), k_a_tensor.item(), k_i_tensor.item(), n_ib_tensor.item(), n_ab_tensor.item(), n_ba_tensor.item(), n_ua_tensor.item(),  loss.item())\n",
    "    print (k_u_tensor.item(), k_a_tensor.item(), k_i_tensor.item(), loss.item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
